C:\Users\dockn\SAM-code\segment-anything-2\sam2\modeling\backbones\hieradet.py:68: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
  x = F.scaled_dot_product_attention(
c:\Users\brian\anaconda3\envs\JY\Lib\site-packages\torch\optim\lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Step 100:	 Accuracy (IoU) =  0.4461756314713211
Step 200:	 Accuracy (IoU) =  0.6511612107944585
Step 300:	 Accuracy (IoU) =  0.730859623659432
Step 400:	 Accuracy (IoU) =  0.7945429279930226
Step 500:	 Accuracy (IoU) =  0.8082661580413979
Step 600:	 Accuracy (IoU) =  0.8409307469131797
Step 700:	 Accuracy (IoU) =  0.8425028982014109
Step 800:	 Accuracy (IoU) =  0.8402678800083447
Step 900:	 Accuracy (IoU) =  0.8401903016082449
Step 1000:	 Accuracy (IoU) =  0.8382424964433313
Step 1100:	 Accuracy (IoU) =  0.845534688917107
Step 1200:	 Accuracy (IoU) =  0.8577477540114754
Step 1300:	 Accuracy (IoU) =  0.8525516519136145
Step 1400:	 Accuracy (IoU) =  0.8477180239219219
Step 1500:	 Accuracy (IoU) =  0.8512807995854672
Step 1600:	 Accuracy (IoU) =  0.8440071023473515
Step 1700:	 Accuracy (IoU) =  0.8419700437423543
Step 1800:	 Accuracy (IoU) =  0.8458152745086347
Step 1900:	 Accuracy (IoU) =  0.8460173187231234
Step 2000:	 Accuracy (IoU) =  0.8586292630811716
Step 2100:	 Accuracy (IoU) =  0.849079045233653
Step 2200:	 Accuracy (IoU) =  0.8388441632475554
Step 2300:	 Accuracy (IoU) =  0.8321476763803456
Step 2400:	 Accuracy (IoU) =  0.8400889784375246
Step 2500:	 Accuracy (IoU) =  0.8608380220830473
Step 2600:	 Accuracy (IoU) =  0.8501141257000229
Step 2700:	 Accuracy (IoU) =  0.8718119524208066
Step 2800:	 Accuracy (IoU) =  0.864310069292914
Step 2900:	 Accuracy (IoU) =  0.8490193825770619
Step 3000:	 Accuracy (IoU) =  0.8452337787035824
IoU: 0.7702
IoU: 0.8438
IoU: 0.9612
IoU: 0.7277
IoU: 0.9305
IoU: 0.9305
IoU: 0.7287
IoU: 0.7292
IoU: 0.7571
IoU: 0.9595
IoU: 0.9607
IoU: 0.9611
IoU: 0.7700
IoU: 0.8509
IoU: 0.9516
IoU: 0.7269
IoU: 0.9421
IoU: 0.9432
IoU: 0.8102
IoU: 0.8125
IoU: 0.9601
IoU: 0.7739
IoU: 0.9563
IoU: 0.9571
IoU: 0.7543
IoU: 0.7674
IoU: 0.7891
IoU: 0.7285
IoU: 0.7398
IoU: 0.9391
IoU: 0.7650
IoU: 0.7884
IoU: 0.9116
IoU: 0.9426
IoU: 0.9426
IoU: 0.9620
IoU: 0.9674
IoU: 0.9646
IoU: 0.9609
IoU: 0.9647
IoU: 0.9632
IoU: 0.9624
IoU: 0.9662
IoU: 0.9596
IoU: 0.9586
IoU: 0.9657
IoU: 0.9628
IoU: 0.9620
IoU: 0.9654
IoU: 0.9633
IoU: 0.9621
IoU: 0.9634
IoU: 0.9604
IoU: 0.9206
IoU: 0.9662
IoU: 0.9643
IoU: 0.9645
IoU: 0.7258
IoU: 0.7450
IoU: 0.9487
IoU: 0.9660
IoU: 0.9631
IoU: 0.9629
IoU: 0.7252
IoU: 0.9506
IoU: 0.9597
IoU: 0.9500
IoU: 0.9565
IoU: 0.9549
IoU: 0.9662
IoU: 0.9660
IoU: 0.9651
IoU: 0.9661
IoU: 0.9633
IoU: 0.9621
IoU: 0.9657
IoU: 0.9597
IoU: 0.9593
IoU: 0.9658
IoU: 0.9646
IoU: 0.9623
IoU: 0.9641
IoU: 0.9629
IoU: 0.9618
IoU: 0.9676
IoU: 0.9649
IoU: 0.9617
IoU: 0.9638
IoU: 0.9634
IoU: 0.9616
IoU: 0.9673
IoU: 0.9637
IoU: 0.9603
IoU: 0.9662
IoU: 0.9599
IoU: 0.9592
IoU: 0.9652
IoU: 0.9617
IoU: 0.9612
IoU: 0.9663
IoU: 0.9637
IoU: 0.9599
IoU: 0.9563
IoU: 0.9598
IoU: 0.9551
